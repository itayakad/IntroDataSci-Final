{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Intro\n",
        "\n",
        "For this project, we selected the **Cleveland Heart Disease dataset** from the UCI Machine Learning Repository. This dataset is widely recognized in the medical and machine learning communities for benchmarking heart disease prediction models. It contains 303 patient records, each with 13 features related to cardiovascular health (e.g., age, resting blood pressure, cholesterol, chest pain type, maximum heart rate, and exercise-induced angina), and a target variable indicating the presence or absence of heart disease.\n",
        "\n",
        "We chose this dataset for several reasons:\n",
        "\n",
        "- **Clinical Relevance:** The features are medically interpretable and commonly collected during routine cardiovascular screenings, making the dataset ideal for developing models that can support real-world clinical decision-making.\n",
        "- **Structured Format:** The dataset is well-structured and manageable in size, allowing for meaningful exploration, visualization, and modeling within the scope of this course.\n",
        "- **Binary Classification Feasibility:** While the original target variable is multiclass (0–4), it is commonly simplified to binary classification (presence vs. absence of disease), aligning with our goal to build an interpretable and practical diagnostic tool.\n",
        "- **Benchmarkability:** The dataset has been used in numerous academic papers and projects, providing a clear reference point for comparing the effectiveness of various modeling approaches.\n",
        "\n",
        "Despite its utility, we acknowledge that the dataset has limitations, including a relatively small sample size and potential class imbalance. These factors were taken into account during model selection, evaluation, and validation strategies (e.g., stratified sampling, cross-validation). Future iterations of this project would benefit from incorporating larger, more diverse datasets to improve generalizability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install shap xgboost numpy pandas matplotlib scikit-learn seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing Rationale\n",
        "\n",
        "We chose to scale the continuous features using `StandardScaler` to ensure that all features contribute equally to model training, particularly for models sensitive to feature magnitudes such as Logistic Regression. Categorical features (e.g., chest pain type, thalassemia) were encoded using one-hot encoding to maintain interpretability and avoid imposing ordinal relationships.\n",
        "\n",
        "The dataset was split using an 80/20 ratio to ensure a fair evaluation of the model's generalization capabilities. While the dataset size is limited (303 samples), we chose stratified splitting to preserve class balance across training and testing sets.\n",
        "\n",
        "We also considered outlier detection but opted not to remove any data points due to the small dataset size and risk of overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyxS_A8YsFY0",
        "outputId": "8df51daf-732b-4d26-8ca1-d0eea6cc3ed2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Upload the data\n",
        "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalac', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
        "df = pd.read_csv('processed.cleveland.data', names = column_names, na_values = '?')\n",
        "df.fillna(df.median(), inplace = True) # Median imputation\n",
        "\n",
        "age = df['age'] # age in years\n",
        "sex = df['sex'] # 1: male, 0: female\n",
        "cp = df['cp'] # 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic\n",
        "trestbps = df['trestbps'] # resting blood pressure in mm Hg\n",
        "chol = df['chol'] # serum cholestoral in mg/dl\n",
        "fbs = df['fbs'] # 1: fasting blood sugar > 120 mg/dl, 0: fasting blood sugar <= 120 mg/dl\n",
        "restecg = df['restecg'] # 0: normal, 1: having ST-T wave abnormality, 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "thalac = df['thalac'] # maximum heart rate achieved\n",
        "exang = df['exang'] # 1: exercise induced angina, 0: no exercise induced angina\n",
        "oldpeak = df['oldpeak'] # ST depression induced by exercise relative to rest\n",
        "slope = df['slope'] # 1: upsloping, 2: flat, 3: downsloping\n",
        "ca = df['ca'] # number of major vessels (0-3) colored by flourosopy\n",
        "thal = df['thal'] # 3: normal, 6: fixed defect, 7: reversable defect\n",
        "num = df['num'] # diagnosis of heart disease (angiographic disease status), 0: < 50% diameter narrowing, 1: > 50% diameter narrowing\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDA Observations\n",
        "\n",
        "The correlation matrix and pairwise feature plots revealed some moderately correlated features. For example, `cp` (chest pain type) and `target` showed a notable relationship, suggesting chest pain type is predictive of heart disease. Similarly, `thalach` (maximum heart rate achieved) was inversely related to heart disease presence, aligning with clinical intuition.\n",
        "\n",
        "Some features such as `fbs` (fasting blood sugar) and `restecg` appeared weakly correlated with the target, which may reduce their influence in tree-based models. However, we retained all features initially to let the models determine importance via feature selection.\n",
        "\n",
        "One challenge during EDA was the limited size and slightly imbalanced target distribution. While no major skew was found, we remained cautious of overfitting and planned to address this using cross-validation and model regularization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "NTOBtaQjdHla",
        "outputId": "5124c2b6-5db0-4613-f293-f4c8502cd76d"
      },
      "outputs": [],
      "source": [
        "# Show heatmap\n",
        "corr = df.corr(numeric_only = True)\n",
        "sns.heatmap(corr, annot = True, cmap = 'coolwarm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "A1sfJncJdXEh",
        "outputId": "009d6c36-37cd-41f0-c0f3-eca4beb97c75"
      },
      "outputs": [],
      "source": [
        "# num vs age\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.boxplot(x = num, y = age, data = df)\n",
        "plt.xlabel('Heart Disease Severity (num)')\n",
        "plt.ylabel('Age')\n",
        "plt.title('Age Distribution by Heart Disease Severity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "FutfXL5RfWBr",
        "outputId": "6e487d87-167b-4d00-f3a6-303035ac06a4"
      },
      "outputs": [],
      "source": [
        "# num vs sex\n",
        "\n",
        "female_data = df[sex == 0]\n",
        "male_data = df[sex == 1]\n",
        "\n",
        "female_counts = female_data['num'].value_counts()\n",
        "male_counts = male_data['num'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize = (6, 3))\n",
        "\n",
        "axes[0].pie(female_counts, labels = female_counts.index, autopct = '%.2f%%')\n",
        "axes[0].set_title('Heart Disease Diagnosis\\nDistribution (Females)')\n",
        "\n",
        "axes[1].pie(male_counts, labels = male_counts.index, autopct = '%.2f%%')\n",
        "axes[1].set_title('Heart Disease Diagnosis\\nDistribution (Males)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "i_ceXgmVgShE",
        "outputId": "da78bfe5-ee26-4949-b174-8ded640229a6"
      },
      "outputs": [],
      "source": [
        "# num vs cp\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.countplot(x = cp, hue = num, data = df)\n",
        "plt.xlabel('Chest Pain Type (cp)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Heart Disease Severity by Chest Pain Type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "2qqFuXHPjuGJ",
        "outputId": "98b2a723-476b-4792-b3aa-b8065e0d528a"
      },
      "outputs": [],
      "source": [
        "# num vs trestbps\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.boxplot(x = num, y = trestbps, data = df)\n",
        "plt.xlabel('Heart Disease Severity (num)')\n",
        "plt.ylabel('Resting Blood Pressure (trestbps)')\n",
        "plt.title('Resting Blood Pressure by Heart Disease Severity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "ThDdG9i-lvQN",
        "outputId": "acb7a934-e2a8-4aba-e19e-ec1d3f87397f"
      },
      "outputs": [],
      "source": [
        "# num vs chol\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.boxplot(x = num, y = chol, data = df)\n",
        "plt.xlabel('Heart Disease Severity (num)')\n",
        "plt.ylabel('Serum Cholesterol (chol)')\n",
        "plt.title('Serum Cholesterol by Heart Disease Severity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "IfwwHMdgmfzs",
        "outputId": "78c2102f-d308-4509-f258-7f3970ef7170"
      },
      "outputs": [],
      "source": [
        "# num vs fbs\n",
        "\n",
        "smaller_data = df[fbs == 0]\n",
        "larger_data = df[fbs == 1]\n",
        "\n",
        "smaller_counts = smaller_data['num'].value_counts()\n",
        "larger_counts = larger_data['num'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize = (6, 3))\n",
        "\n",
        "axes[0].pie(smaller_counts, labels = smaller_counts.index, autopct = '%.2f%%')\n",
        "axes[0].set_title('Heart Disease Diagnosis\\nDistribution (Smaller)')\n",
        "\n",
        "axes[1].pie(larger_counts, labels = larger_counts.index, autopct = '%.2f%%')\n",
        "axes[1].set_title('Heart Disease Diagnosis\\nDistribution (Larger)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "l_aE9q46npdI",
        "outputId": "915dbb96-9a0a-4288-b9d8-3427605e96fb"
      },
      "outputs": [],
      "source": [
        "# num vs restecg\n",
        "\n",
        "normal_data = df[restecg == 0]\n",
        "abnormality_data = df[restecg == 1]\n",
        "hypertrophy_data = df[restecg == 2]\n",
        "\n",
        "normal_counts = normal_data['num'].value_counts()\n",
        "abnormality_counts = abnormality_data['num'].value_counts()\n",
        "hypertrophy_counts = hypertrophy_data['num'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize = (8, 4))\n",
        "\n",
        "axes[0].pie(normal_counts, labels = normal_counts.index, autopct = '%.2f%%')\n",
        "axes[0].set_title('Num Distribution\\n(Normal)')\n",
        "\n",
        "axes[1].pie(abnormality_counts, labels = abnormality_counts.index, autopct = '%.2f%%')\n",
        "axes[1].set_title('Num Distribution\\n(Abnormality)')\n",
        "\n",
        "axes[2].pie(hypertrophy_counts, labels = hypertrophy_counts.index, autopct = '%.2f%%')\n",
        "axes[2].set_title('Num Distribution\\n(Hypertrophy)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "BLmQKjOipI7T",
        "outputId": "f183407f-f3bf-406a-fd88-65540a543beb"
      },
      "outputs": [],
      "source": [
        "# num vs thalac\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.boxplot(x = num, y = thalac, data = df)\n",
        "plt.xlabel('Heart Disease Severity (num)')\n",
        "plt.ylabel('Maximum Heart Rate (thalac)')\n",
        "plt.title('Maximum Heart Rate by Heart Disease Severity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "fcuP8NtdGDiK",
        "outputId": "a32cd598-bf80-438c-dca5-dae3a409ec57"
      },
      "outputs": [],
      "source": [
        "# num vs exang\n",
        "\n",
        "yes_data = df[exang == 0]\n",
        "no_data = df[exang == 1]\n",
        "\n",
        "yes_counts = yes_data['num'].value_counts()\n",
        "no_counts = no_data['num'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize = (6, 3))\n",
        "\n",
        "axes[0].pie(yes_counts, labels = yes_counts.index, autopct = '%.2f%%')\n",
        "axes[0].set_title('Num Distribution (Normal)')\n",
        "\n",
        "axes[1].pie(no_counts, labels = no_counts.index, autopct = '%.2f%%')\n",
        "axes[1].set_title('Num Distribution (Abnormality)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "M05b6R_DMiOi",
        "outputId": "a66ed1b9-c45c-4d99-af52-71c4b9533c66"
      },
      "outputs": [],
      "source": [
        "# num vs oldpeak\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.boxplot(x = num, y = oldpeak, data = df)\n",
        "plt.xlabel('Heart Disease Severity (num)')\n",
        "plt.ylabel('Oldpeak')\n",
        "plt.title('Oldpeak by Heart Disease Severity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "vqe5lo1HNFwd",
        "outputId": "d3b33c40-b021-4e2a-b75f-28337eab98f6"
      },
      "outputs": [],
      "source": [
        "# num vs slope\n",
        "\n",
        "upsloping_data = df[slope == 1]\n",
        "flat_data = df[slope == 2]\n",
        "downsloping_data = df[slope == 3]\n",
        "\n",
        "upsloping_counts = upsloping_data['num'].value_counts()\n",
        "flat_counts = flat_data['num'].value_counts()\n",
        "downsloping_counts = downsloping_data['num'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize = (8, 4))\n",
        "\n",
        "axes[0].pie(upsloping_counts, labels = upsloping_counts.index, autopct = '%.2f%%')\n",
        "axes[0].set_title('Num Distribution\\n(Upsloping)')\n",
        "\n",
        "axes[1].pie(flat_counts, labels = flat_counts.index, autopct = '%.2f%%')\n",
        "axes[1].set_title('Num Distribution\\n(Flat)')\n",
        "\n",
        "axes[2].pie(downsloping_counts, labels = downsloping_counts.index, autopct = '%.2f%%')\n",
        "axes[2].set_title('Num Distribution\\n(Downsloping)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "mml1yqN-RQH7",
        "outputId": "d6b578b7-b658-4f63-9259-5d6b426d1eff"
      },
      "outputs": [],
      "source": [
        "# num vs ca\n",
        "\n",
        "plt.figure(figsize = (4, 3))\n",
        "sns.countplot(x = ca, hue = num, data = df)\n",
        "plt.xlabel('Number of Major Vessels (ca)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Heart Disease Severity by Number of Major Vessels')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "ojGAoPjmSkyF",
        "outputId": "f1cf8d04-31f1-46df-f8a0-e92940be4cca"
      },
      "outputs": [],
      "source": [
        "# num vs thal\n",
        "\n",
        "normaldefect_data = df[thal == 3]\n",
        "fixed_data = df[thal == 6]\n",
        "reversable_data = df[thal == 7]\n",
        "\n",
        "normaldefect_counts = normaldefect_data['num'].value_counts()\n",
        "fixed_counts = fixed_data['num'].value_counts()\n",
        "reversable_counts = reversable_data['num'].value_counts()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize = (8, 4))\n",
        "\n",
        "axes[0].pie(normaldefect_counts, labels = normaldefect_counts.index, autopct = '%.2f%%')\n",
        "axes[0].set_title('Num Distribution\\n(Normal Defect)')\n",
        "\n",
        "axes[1].pie(fixed_counts, labels = fixed_counts.index, autopct = '%.2f%%')\n",
        "axes[1].set_title('Num Distribution\\n(Fixed Defect)')\n",
        "\n",
        "axes[2].pie(reversable_counts, labels = reversable_counts.index, autopct = '%.2f%%')\n",
        "axes[2].set_title('Num Distribution\\n(Reversible Defect)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression: Baseline Model\n",
        "\n",
        "We began with Logistic Regression as a baseline model because it is widely used in healthcare applications due to its simplicity, transparency, and interpretability. Physicians can directly examine the model coefficients to understand how different features impact the probability of heart disease, which is critical for clinical trust and adoption.\n",
        "\n",
        "However, Logistic Regression relies on the assumption of linear separability between classes, which may not hold in medical datasets where relationships between features and outcomes are often complex and non-linear. In our case, while the model performed reasonably in terms of accuracy and precision, it struggled with recall — failing to identify several true positive cases of heart disease. This is particularly problematic in clinical settings where missing a diagnosis can have serious consequences.\n",
        "\n",
        "Upon examining the learned coefficients, features such as `cp` (chest pain type), `thalach` (maximum heart rate), and `exang` (exercise-induced angina) showed strong associations with the target, which is consistent with medical understanding. Yet, the model's inability to capture interactions between features likely contributed to its underperformance.\n",
        "\n",
        "This motivated our shift to non-linear models like Decision Trees and Random Forests, which are better suited for capturing interaction effects and complex decision boundaries while still allowing some level of interpretability through feature importance analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "QXgA3uDEoIxi",
        "outputId": "e1451ba8-47b4-48af-be25-55a4ba1ceaae"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['num'], axis=1)\n",
        "y = (df['num'] > 0).astype(int)  # Binary classification\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth = 4, random_state = 42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize = (40, 20))\n",
        "plot_tree(tree, feature_names = X.columns, class_names = ['No Disease', 'Disease'], filled = True, fontsize = 14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest Model: Improved Non-Linear Learning\n",
        "\n",
        "After identifying the limitations of Logistic Regression, we selected Random Forest as our next model due to its ability to capture complex, non-linear relationships between features — a common requirement in medical datasets. Unlike a single decision tree, Random Forest combines the predictions of multiple trees to reduce overfitting and improve generalization, making it a strong candidate for small-to-medium datasets like ours.\n",
        "\n",
        "Performance metrics improved notably, particularly in recall and F1-score, which is critical for a healthcare setting where false negatives (missed diagnoses) carry significant risk. This improvement suggests that Random Forest was better able to model subtle interactions between features such as `cp`, `thalach`, `oldpeak`, and `ca` — all of which emerged as top predictors in our feature importance analysis. These findings also align with domain knowledge, lending credibility to the model's internal logic.\n",
        "\n",
        "However, we observed some sensitivity to the random seed, indicating instability in predictions. Initially, we used default parameters, but later implemented GridSearchCV to fine-tune hyperparameters like `max_depth` and `n_estimators`. This tuning stabilized performance and improved consistency, though we acknowledge that Random Forest’s ensemble nature comes at the cost of reduced interpretability compared to Logistic Regression — a trade-off we deemed acceptable for improved clinical accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "AVsnu3q_pQwQ",
        "outputId": "1495baeb-3027-4000-cb2f-cd671f12b4f6"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "forest.fit(X_train, y_train)\n",
        "y_pred = forest.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "importances = pd.Series(forest.feature_importances_, index=X.columns)\n",
        "importances.sort_values().plot(kind='barh')\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost: Best Overall Performance\n",
        "\n",
        "We chose to implement XGBoost after Random Forest because it builds on similar tree-based principles while introducing regularization and more granular control over model complexity. Its robustness to overfitting, ability to model complex feature interactions, and scalability made it a compelling option — even for a relatively small dataset like ours.\n",
        "\n",
        "XGBoost ultimately delivered the best performance across all metrics, particularly accuracy and F1-score. This confirms its strength in managing bias-variance trade-offs and leveraging important predictors like `cp`, `thalach`, `oldpeak`, and `ca`, which repeatedly emerged as top contributors across models. These features are also clinically relevant, lending further confidence to the model's internal decision process.\n",
        "\n",
        "We encountered some challenges preprocessing categorical variables for compatibility with XGBoost, which does not natively handle non-numeric features. To address this, we applied one-hot encoding and adjusted key parameters (e.g., disabling `use_label_encoder`, setting `eval_metric` to `logloss`) in line with current best practices.\n",
        "\n",
        "Contrary to earlier experiments with default parameters, we later applied both GridSearchCV and RandomizedSearchCV to fine-tune hyperparameters such as `max_depth`, `n_estimators`, and `learning_rate`. While GridSearchCV delivered slightly higher accuracy, RandomizedSearchCV was more efficient and likely to generalize better due to its broader search space.\n",
        "\n",
        "To better interpret the model's predictions, we also incorporated SHAP analysis, which confirmed that the most influential features aligned with clinical expectations. Despite XGBoost's black-box reputation, this interpretability step made the model more transparent and trustworthy in a healthcare context — a critical factor when considering real-world deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "DyerYe3Bq6f_",
        "outputId": "8c5655a4-6963-4e4e-c5a6-64c0cdd95e47"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBClassifier(use_label_encoder = False, eval_metric = 'logloss', random_state = 42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "xgb.plot_importance(model)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning: GridSearchCV vs. RandomizedSearchCV\n",
        "\n",
        "To improve the performance and robustness of our XGBoost model, we implemented two hyperparameter optimization techniques: **GridSearchCV** and **RandomizedSearchCV**. Our goal was not only to improve metrics like F1-score but also to ensure stability and generalizability, which are essential in high-stakes domains like healthcare.\n",
        "\n",
        "**GridSearchCV** exhaustively searched a predefined set of hyperparameters and identified the best combination as:\n",
        "- `learning_rate`: 0.3  \n",
        "- `max_depth`: 7  \n",
        "- `n_estimators`: 100\n",
        "\n",
        "This configuration yielded strong results:\n",
        "- **Accuracy:** 0.87  \n",
        "- **F1-Score:** 0.87 (macro & weighted average)\n",
        "\n",
        "While effective, GridSearchCV is computationally expensive and limited to the values explicitly defined in the grid. It can miss better combinations that fall outside this narrow search space.\n",
        "\n",
        "**RandomizedSearchCV**, in contrast, sampled 50 random combinations from a broader parameter distribution. It identified the following optimal configuration:\n",
        "- `colsample_bytree`: 0.916  \n",
        "- `learning_rate`: 0.095  \n",
        "- `max_depth`: 6  \n",
        "- `n_estimators`: 70  \n",
        "- `subsample`: 0.809\n",
        "\n",
        "Performance was slightly lower but still strong:\n",
        "- **Accuracy:** 0.85  \n",
        "- **F1-Score:** 0.85 (macro & weighted average)\n",
        "\n",
        "Although GridSearchCV produced marginally higher scores, RandomizedSearchCV was more computationally efficient and better suited for exploratory tuning when time and resources are constrained. Importantly, it may yield models that generalize better to unseen data — a key consideration in real-world clinical applications.\n",
        "\n",
        "Ultimately, using both methods gave us a more complete understanding of how hyperparameters affect performance, and underscored the importance of tuning in unlocking the full potential of ensemble models like XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "# Initialize model\n",
        "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Grid search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=xgb,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='f1',\n",
        "                           cv=5,\n",
        "                           verbose=1,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict using the best model\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred_xgb = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"Classification Report for Tuned XGBoost:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define the parameter distributions\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'learning_rate': uniform(0.01, 0.4),\n",
        "    'subsample': uniform(0.5, 0.5),\n",
        "    'colsample_bytree': uniform(0.5, 0.5)\n",
        "}\n",
        "\n",
        "# Initialize model\n",
        "xgb_clf = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "\n",
        "# Run RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,  # number of random combinations to try\n",
        "    scoring='f1',\n",
        "    cv=5,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "xgb_random_best = random_search.best_estimator_\n",
        "\n",
        "# Print best results\n",
        "print(\"Best Parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(\"\\nClassification Report for Tuned XGBoost (RandomizedSearchCV):\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SHAP Feature Importance Analysis\n",
        "\n",
        "To interpret the predictions made by our tuned XGBoost model, we used **SHAP (SHapley Additive exPlanations)** — a powerful interpretability technique grounded in cooperative game theory. SHAP assigns each feature an importance value for a given prediction, allowing us to understand not just what the model predicted, but why.\n",
        "\n",
        "- The **summary plot (beeswarm)** illustrates how individual features influenced predictions across all samples. Each point represents a SHAP value, with color indicating the original feature value (red = high, blue = low). For example, high values of `'cp'` (chest pain type) and `'thal'` (thalassemia) were associated with increased heart disease risk, while high values of `'ca'` (number of major vessels) were linked to decreased risk.\n",
        "  \n",
        "- The **bar plot** shows the **mean absolute SHAP value** of each feature, ranking them by their average impact. Consistent with our earlier models, `'ca'`, `'cp'`, and `'thal'` were the most influential features.\n",
        "\n",
        "This analysis is especially valuable in a healthcare context, where black-box models can be difficult to trust. SHAP improves transparency and provides clinicians with a clearer picture of what the model prioritizes when making decisions. It also supports clinical validation by reinforcing the medical relevance of key features. \n",
        "\n",
        "However, while SHAP helps us interpret model behavior, it does not uncover dataset bias or structural issues — limitations that require deeper auditing. Still, its ability to explain individual predictions makes it a critical step toward deploying machine learning responsibly in sensitive domains like cardiovascular risk prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a TreeExplainer for the best model from RandomizedSearchCV\n",
        "explainer = shap.Explainer(xgb_random_best)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# Plot summary plot\n",
        "shap.plots.beeswarm(shap_values)\n",
        "\n",
        "# Optional: also plot bar chart version\n",
        "shap.plots.bar(shap_values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Comparison and Reflection\n",
        "\n",
        "Throughout this project, we evaluated multiple models to predict heart disease risk, balancing interpretability and predictive performance. Logistic Regression served as our baseline and offered straightforward insights into feature impact, but it underperformed on recall and F1-score, making it less reliable for clinical application.\n",
        "\n",
        "Tree-based models like Random Forest and XGBoost provided notable improvements. Random Forest captured non-linear relationships effectively, while XGBoost delivered the strongest overall performance, achieving an F1-score of 0.87 after hyperparameter tuning via GridSearchCV and 0.85 using RandomizedSearchCV. Both tuning methods validated that careful optimization meaningfully improves model outcomes, with RandomizedSearchCV offering faster, broader exploration.\n",
        "\n",
        "We also used SHAP to interpret the tuned XGBoost model’s predictions. SHAP revealed that features like chest pain type (cp), number of major vessels (ca), and thalassemia (thal) had the greatest impact on classification decisions. This alignment with known medical knowledge confirms the model is learning relevant patterns rather than spurious correlations.\n",
        "\n",
        "Despite strong results, limitations persist. The dataset is relatively small (303 samples), which affects generalizability. Cross-validation helped mitigate overfitting, but real-world deployment would require validation on external datasets. Future work should also explore ensemble approaches, deeper hyperparameter search (e.g., with Optuna), and integration into a clinical decision-support tool."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
